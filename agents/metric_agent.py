"""
æŒ‡æ ‡ç®¡ç†Agent - å¤„ç†æŒ‡æ ‡çš„åˆ›å»ºã€æ›´æ–°å’ŒæŸ¥è¯¢
ä½¿ç”¨LangGraphå·¥ä½œæµ
"""
from typing import Dict, List, Any, Optional, AsyncGenerator
from datetime import datetime
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

from .base_agent import BaseAgent, AgentConfig, AgentResponse
from models import MetricOperationType
from tools import (
    query_metric_by_name_zh, get_metric_domains
)


# LLMè¾“å‡ºè§£ææ¨¡å‹
class MetricAnalysisModel(BaseModel):
    """æŒ‡æ ‡åˆ†æç»“æœæ¨¡å‹"""
    operation_type: str = Field(
        description="æ“ä½œç±»å‹ï¼šcreate/update/queryï¼Œæ ¹æ®ç”¨æˆ·æ„å›¾åˆ¤æ–­",
        examples=["create", "update", "query"]
    )
    target_metric: str = Field(
        default="",
        description="ç›®æ ‡æŒ‡æ ‡åç§°ï¼Œå¦‚æœæ˜¯ä¿®æ”¹æ“ä½œæ—¶æŒ‡å®šè¦ä¿®æ”¹çš„æŒ‡æ ‡"
    )
    metric_name: str = Field(
        description="æŒ‡æ ‡è‹±æ–‡åç§°ï¼ŒæŒ‡æ ‡çš„è‹±æ–‡æ ‡è¯†ç¬¦ï¼Œé€šå¸¸ä½¿ç”¨ä¸‹åˆ’çº¿åˆ†éš”çš„å°å†™å•è¯",
        examples=["monthly_active_users", "order_conversion_rate", "customer_lifetime_value", "daily_sales_amount"]
    )
    metric_name_zh: str = Field(
        description="æŒ‡æ ‡ä¸­æ–‡åç§°ï¼Œä»ç”¨æˆ·è¾“å…¥ä¸­å‡†ç¡®æå–çš„æ ¸å¿ƒæŒ‡æ ‡åç§°",
        examples=["æœˆåº¦æ´»è·ƒç”¨æˆ·æ•°", "è®¢å•è½¬åŒ–ç‡", "å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼", "æ—¥é”€å”®é¢"]
    )
    metric_type: str = Field(
        default="IA",
        description="æŒ‡æ ‡ç±»å‹ï¼šIAåŸå­æŒ‡æ ‡(ç›´æ¥ç»Ÿè®¡)/IBæ´¾ç”ŸæŒ‡æ ‡(è®¡ç®—å¾—å‡º)",
        examples=["IA", "IB"]
    )
    metric_level: str = Field(
        default="T2",
        description="æŒ‡æ ‡é‡è¦ç­‰çº§ï¼šT1æ ¸å¿ƒæŒ‡æ ‡/T2é‡è¦æŒ‡æ ‡/T3ä¸€èˆ¬æŒ‡æ ‡",
        examples=["T1", "T2", "T3"]
    )
    application_scenarios: str = Field(
        default="HIVE_OFFLINE",
        description="åº”ç”¨åœºæ™¯ï¼šHIVE_OFFLINEç¦»çº¿æ•°ä»“/OLAP_ONLINEåœ¨çº¿åˆ†æ",
        examples=["HIVE_OFFLINE", "OLAP_ONLINE"]
    )
    process_domain: str = Field(
        default="domain_001",
        description="ä¸šåŠ¡åŸŸIDï¼Œä»å¯ç”¨åŸŸä¸­é€‰æ‹©æœ€åˆé€‚çš„",
        examples=["domain_001", "domain_002", "domain_003", "domain_004"]
    )
    safe_level: str = Field(
        default="S1",
        description="å®‰å…¨ç­‰çº§ï¼šS1æ™®é€šæ•°æ®/S2/S3/S4/S5å›½å¯†æ•°æ®",
        examples=["S1", "S2", "S3", "S4", "S5"]
    )
    business_owner: str = Field(
        default="å¾…æŒ‡å®š",
        description="ä¸šåŠ¡è´Ÿè´£äººï¼Œæ ¹æ®æŒ‡æ ‡æ€§è´¨æ¨æ–­åˆé€‚è§’è‰²",
        examples=["äº§å“ç»ç†", "è¿è¥æ€»ç›‘", "è´¢åŠ¡ä¸»ç®¡", "æ•°æ®åˆ†æå¸ˆ"]
    )
    business_team: str = Field(
        default="å¾…æŒ‡å®š",
        description="ä¸šåŠ¡å±ä¸»å›¢é˜Ÿï¼Œæ ¹æ®æŒ‡æ ‡ä¸šåŠ¡é¢†åŸŸç¡®å®š",
        examples=["äº§å“å›¢é˜Ÿ", "è¿è¥å›¢é˜Ÿ", "è´¢åŠ¡å›¢é˜Ÿ", "å¸‚åœºå›¢é˜Ÿ"]
    )
    statistical_object: str = Field(
        default="å¾…å®šä¹‰",
        description="ç»Ÿè®¡å¯¹è±¡ï¼ŒæŒ‡æ ‡ç»Ÿè®¡çš„ä¸»ä½“",
        examples=["ç”¨æˆ·", "è®¢å•", "å•†å“", "è®¿é—®", "æ´»åŠ¨", "å®¢æˆ·", "äº¤æ˜“"]
    )
    statistical_rule: str = Field(
        default="å¾…å®šä¹‰",
        description="ç»Ÿè®¡è§„åˆ™ï¼Œä¸šåŠ¡å±‚é¢çš„ç»Ÿè®¡é€»è¾‘ï¼Œç”¨è‡ªç„¶è¯­è¨€æè¿°"
    )
    statistical_rule_it: str = Field(
        default="å¾…å®šä¹‰",
        description="ITå£å¾„ï¼ŒæŠ€æœ¯å®ç°çš„å…·ä½“SQLæˆ–æŠ€æœ¯è§„åˆ™"
    )
    statistical_time: str = Field(
        default="å¾…å®šä¹‰",
        description="ç»Ÿè®¡æ—¶é—´ç²’åº¦ï¼ŒæŒ‡æ ‡ç»Ÿè®¡çš„æ—¶é—´å‘¨æœŸ",
        examples=["å®æ—¶", "å°æ—¶", "æ—¥", "å‘¨", "æœˆ", "å­£åº¦", "å¹´"]
    )
    unit: str = Field(
        default="ä¸ª",
        description="æŒ‡æ ‡å•ä½ï¼ŒæŒ‡æ ‡æ•°å€¼çš„è®¡é‡å•ä½",
        examples=["ä¸ª", "äºº", "å…ƒ", "%", "æ¬¡", "ç¬”", "å¤©", "å°æ—¶", "GB", "MB"]
    )
    business_caliber: str = Field(
        default="",
        description="æŒ‡æ ‡ä¸šåŠ¡å£å¾„ï¼Œè¯¦ç»†çš„ä¸šåŠ¡å«ä¹‰è¯´æ˜ï¼Œè§£é‡ŠæŒ‡æ ‡çš„å®é™…ä¸šåŠ¡æ„ä¹‰å’Œä»·å€¼"
    )
    requirements: List[str] = Field(
        default_factory=list,
        description="å…¶ä»–éœ€æ±‚åˆ—è¡¨ï¼Œç”¨æˆ·æåˆ°çš„ç‰¹æ®Šè¦æ±‚æˆ–çº¦æŸæ¡ä»¶"
    )

    model_config = {
        "json_schema_extra": {
            "example": {
                "operation_type": "create",
                "target_metric": "",
                "metric_name": "monthly_active_users",
                "metric_name_zh": "æœˆåº¦æ´»è·ƒç”¨æˆ·æ•°",
                "metric_type": "IA",
                "metric_level": "T1",
                "application_scenarios": "HIVE_OFFLINE",
                "process_domain": "domain_002",
                "safe_level": "S1",
                "business_owner": "äº§å“ç»ç†",
                "business_team": "ç”¨æˆ·å¢é•¿å›¢é˜Ÿ",
                "statistical_object": "ç”¨æˆ·",
                "statistical_rule": "ç»Ÿè®¡å½“æœˆå†…æœ‰ç™»å½•æˆ–ä½¿ç”¨è¡Œä¸ºçš„å»é‡ç”¨æˆ·æ•°é‡",
                "statistical_rule_it": "SELECT COUNT(DISTINCT user_id) FROM user_activity WHERE activity_date >= DATE_TRUNC('month', CURRENT_DATE) AND activity_type IN ('login', 'page_view', 'click')",
                "statistical_time": "æœˆ",
                "unit": "äºº",
                "business_caliber": "è¡¡é‡äº§å“æœˆåº¦æ´»è·ƒåº¦çš„é‡è¦æŒ‡æ ‡ï¼Œåæ˜ ç”¨æˆ·ç²˜æ€§å’Œäº§å“å¸å¼•åŠ›ï¼Œç”¨äºæŒ‡å¯¼è¿è¥ç­–ç•¥å’Œäº§å“è¿­ä»£",
                "requirements": ["åŒ…å«æ‰€æœ‰ç”¨æˆ·ç±»å‹", "æ’é™¤æµ‹è¯•è´¦å·", "æŒ‰è‡ªç„¶æœˆç»Ÿè®¡"]
            }
        }
    }


class MetricManagementAgent(BaseAgent):
    """æŒ‡æ ‡ç®¡ç†Agent"""

    def __init__(self, config: AgentConfig):
        super().__init__(config)
        self._logger.info("ğŸ“Š åˆå§‹åŒ–æŒ‡æ ‡ç®¡ç†Agent...")

        # åˆ›å»ºè¾“å‡ºè§£æå™¨
        self.analysis_parser = PydanticOutputParser(pydantic_object=MetricAnalysisModel)

        # åˆ›å»ºå·¥ä½œæµå›¾
        self.graph = self._create_workflow()
        self._logger.info("âœ… æŒ‡æ ‡ç®¡ç†Agentåˆå§‹åŒ–å®Œæˆ")

    def _create_workflow(self):
        """åˆ›å»ºLangGraphå·¥ä½œæµ"""
        from langgraph.graph import StateGraph, START, END
        from typing_extensions import TypedDict, Annotated
        from langgraph.graph.message import add_messages

        class AgentState(TypedDict):
            messages: Annotated[list, add_messages]
            user_input: str
            analysis_result: Optional[Dict[str, Any]]
            existing_metric: Optional[Dict[str, Any]]
            final_metric: Optional[Dict[str, Any]]
            success: bool

        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("analyze_request", self._analyze_request)
        workflow.add_node("query_metric", self._query_metric)
        workflow.add_node("execute_operation", self._execute_operation)

        # æ·»åŠ è¾¹
        workflow.add_edge(START, "analyze_request")
        workflow.add_edge("analyze_request", "query_metric")
        workflow.add_edge("query_metric", "execute_operation")
        workflow.add_edge("execute_operation", END)

        return workflow.compile()

    async def process(self, user_input: str, **kwargs) -> AgentResponse:
        """å¤„ç†ç”¨æˆ·è¾“å…¥çš„æ ¸å¿ƒæ–¹æ³•"""
        self._logger.info("ğŸ“Š å¼€å§‹æ‰§è¡ŒæŒ‡æ ‡ç®¡ç†å·¥ä½œæµ")

        initial_state = {
            "messages": [],
            "user_input": user_input,
            "analysis_result": None,
            "existing_metric": None,
            "final_metric": None,
            "success": False
        }

        try:
            result = await self.graph.ainvoke(initial_state)
            success = result.get("success", False)
            final_metric = result.get("final_metric")
            analysis_result = result.get("analysis_result")
            existing_metric = result.get("existing_metric")

            self._logger.info("âœ… æŒ‡æ ‡ç®¡ç†å·¥ä½œæµæ‰§è¡Œå®Œæˆ")

            return AgentResponse(
                success=success,
                data={
                    "metric": final_metric,
                    "existing_metric": existing_metric,
                    "analysis": analysis_result
                }
            )

        except Exception as e:
            self._logger.error(f"ğŸ’¥ æŒ‡æ ‡ç®¡ç†å·¥ä½œæµå¼‚å¸¸: {e}")
            return AgentResponse(
                success=False,
                error=f"æŒ‡æ ‡ç®¡ç†å·¥ä½œæµå¼‚å¸¸: {str(e)}"
            )

    async def process_stream(self, user_input: str, **kwargs) -> AsyncGenerator[Dict[str, Any], None]:
        """å¤„ç†ç”¨æˆ·è¾“å…¥çš„æµå¼æ–¹æ³•"""
        self._logger.info("ğŸ“Š å¼€å§‹æ‰§è¡ŒæŒ‡æ ‡ç®¡ç†å·¥ä½œæµï¼ˆæµå¼ï¼‰")

        initial_state = {
            "messages": [],
            "user_input": user_input,
            "analysis_result": None,
            "existing_metric": None,
            "final_metric": None,
            "success": False
        }

        try:
            # å…ˆå‘é€å¼€å§‹æ¶ˆæ¯
            yield {
                "step": "starting",
                "data": {"user_input": user_input},
                "message": "ğŸ” å¼€å§‹åˆ†ææ‚¨çš„æŒ‡æ ‡ç®¡ç†éœ€æ±‚...",
                "timestamp": datetime.now().isoformat()
            }

            # ä½¿ç”¨LangGraphçš„æµå¼æ‰§è¡Œ
            async for output in self.graph.astream(initial_state):
                node_name = list(output.keys())[0]
                node_state = output[node_name]

                # æ„å»ºæµå¼è¾“å‡ºæ•°æ®
                chunk = {
                    "step": node_name,
                    "data": {
                        "node": node_name,
                        "state_summary": {
                            "has_analysis": node_state.get("analysis_result") is not None,
                            "has_existing_metric": node_state.get("existing_metric") is not None,
                            "has_final_metric": node_state.get("final_metric") is not None,
                            "success": node_state.get("success", False)
                        }
                    },
                    "message": f"æ‰§è¡Œæ­¥éª¤: {node_name}"
                }

                # æ·»åŠ æ­¥éª¤ç‰¹å®šçš„æ•°æ®
                if node_name == "analyze_request":
                    analysis = node_state.get("analysis_result", {})
                    if analysis:
                        chunk["data"]["analysis"] = analysis
                        chunk["message"] = f"âœ… éœ€æ±‚åˆ†æå®Œæˆ: {analysis.get('metric_name', 'N/A')} - {analysis.get('operation_type', 'N/A')}"
                    else:
                        chunk["message"] = "ğŸ“ æ­£åœ¨åˆ†ææ‚¨çš„éœ€æ±‚..."

                elif node_name == "query_metric":
                    existing = node_state.get("existing_metric")
                    if existing:
                        chunk["data"]["existing_metric"] = existing
                        chunk["message"] = f"ğŸ“‹ æ‰¾åˆ°å·²å­˜åœ¨æŒ‡æ ‡: {existing.get('nameZh', 'N/A')} ({existing.get('code', 'N/A')})"
                    else:
                        chunk["message"] = "â„¹ï¸ æœªæ‰¾åˆ°å·²å­˜åœ¨æŒ‡æ ‡ï¼Œå°†åˆ›å»ºæ–°æŒ‡æ ‡"

                elif node_name == "execute_operation":
                    final_metric = node_state.get("final_metric")
                    success = node_state.get("success", False)
                    if final_metric and success:
                        chunk["data"]["final_metric"] = final_metric
                        chunk["message"] = f"ğŸ‰ æŒ‡æ ‡å¤„ç†å®Œæˆ: {final_metric.get('nameZh', 'N/A')}"
                    else:
                        chunk["message"] = "âŒ æŒ‡æ ‡å¤„ç†å¤±è´¥"

                chunk["timestamp"] = datetime.now().isoformat()
                yield chunk

            # å‘é€æœ€ç»ˆå®Œæˆæ¶ˆæ¯
            final_chunk = {
                "step": "completed",
                "data": {"workflow_completed": True},
                "message": "âœ… æŒ‡æ ‡ç®¡ç†å·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                "timestamp": datetime.now().isoformat()
            }
            yield final_chunk

        except Exception as e:
            error_chunk = {
                "step": "error",
                "data": {"error": str(e)},
                "message": f"âŒ æŒ‡æ ‡ç®¡ç†å·¥ä½œæµå¼‚å¸¸: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
            yield error_chunk

    # ========== LangGraph å·¥ä½œæµèŠ‚ç‚¹ ==========

    async def _analyze_request(self, state) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·éœ€æ±‚èŠ‚ç‚¹"""
        user_input = state["user_input"]
        self._logger.info("ğŸ” åˆ†æç”¨æˆ·æŒ‡æ ‡ç®¡ç†éœ€æ±‚")

        # è·å–ä¸šåŠ¡åŸŸä¿¡æ¯
        try:
            domains_info = await get_metric_domains()
            domains_text = "\n".join([f"- {domain['id']}: {domain['nameZh']}" for domain in domains_info])
        except Exception as e:
            self._logger.warning(f"âš ï¸ è·å–ä¸šåŠ¡åŸŸä¿¡æ¯å¤±è´¥: {e}")
            domains_info = []
            domains_text = "- domain_001: è´¢åŠ¡\n- domain_002: ç”¨æˆ·\n- domain_003: äº§å“\n- domain_004: è¿è¥"

        prompt = ChatPromptTemplate.from_template("""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œè¯·ä»”ç»†åˆ†æç”¨æˆ·çš„æŒ‡æ ‡ç®¡ç†éœ€æ±‚ï¼Œæå–å®Œæ•´çš„æŒ‡æ ‡ä¿¡æ¯ã€‚ç†è§£ç”¨æˆ·çš„å…·ä½“ä¸šåŠ¡åœºæ™¯å’Œéœ€æ±‚ç»†èŠ‚ã€‚

        ç”¨æˆ·è¾“å…¥ï¼š{user_input}

        å¯ç”¨ä¸šåŠ¡åŸŸï¼š
        {domains_text}

        {format_instructions}

        è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥æå–ä»¥ä¸‹è¯¦ç»†ä¿¡æ¯ã€‚ä»”ç»†åˆ†æç”¨æˆ·çš„ä¸šåŠ¡åœºæ™¯ï¼Œæå–æˆ–æ¨æ–­å‡ºåˆç†çš„æŒ‡æ ‡å±æ€§ï¼š

        1. operation_type: æ“ä½œç±»å‹ï¼ˆcreate/update/queryï¼‰
        2. metric_name: æŒ‡æ ‡è‹±æ–‡åç§°ï¼ˆå¿…å¡«ï¼ŒåŸºäºä¸­æ–‡åç§°ç”Ÿæˆçš„è‹±æ–‡æ ‡è¯†ç¬¦ï¼Œé€šå¸¸ä½¿ç”¨ä¸‹åˆ’çº¿åˆ†éš”çš„å°å†™å•è¯ï¼‰
        3. metric_name_zh: æŒ‡æ ‡ä¸­æ–‡åç§°ï¼ˆå¿…å¡«ï¼Œä»ç”¨æˆ·è¾“å…¥ä¸­å‡†ç¡®æå–çš„æ ¸å¿ƒæŒ‡æ ‡åç§°ï¼‰
        4. metric_type: æŒ‡æ ‡ç±»å‹ï¼ˆIAåŸå­æŒ‡æ ‡/IBæ´¾ç”ŸæŒ‡æ ‡ï¼‰
           - åŸå­æŒ‡æ ‡ï¼šç›´æ¥ä»ä¸šåŠ¡ç³»ç»Ÿç»Ÿè®¡å¾—åˆ°çš„åŸå§‹æŒ‡æ ‡ï¼Œå¦‚"ç”¨æˆ·æ•°"ã€"è®¢å•é‡"
           - æ´¾ç”ŸæŒ‡æ ‡ï¼šåŸºäºå…¶ä»–æŒ‡æ ‡è®¡ç®—å¾—å‡ºçš„æŒ‡æ ‡ï¼Œå¦‚"è½¬åŒ–ç‡"ã€"äººå‡æ”¶å…¥"
        5. metric_level: æŒ‡æ ‡é‡è¦ç­‰çº§ï¼ˆT1æœ€é‡è¦/T2ä¸­ç­‰/T3ä¸€èˆ¬ï¼‰
           - T1ï¼šæ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡ï¼Œç›´æ¥å½±å“ä¸šåŠ¡å†³ç­–
           - T2ï¼šé‡è¦ä¸šåŠ¡æŒ‡æ ‡ï¼Œå¸¸è§„ç›‘æ§ä½¿ç”¨
           - T3ï¼šä¸€èˆ¬æŒ‡æ ‡ï¼Œè¾…åŠ©åˆ†æä½¿ç”¨
        6. application_scenarios: åº”ç”¨åœºæ™¯ï¼ˆHIVE_OFFLINEç¦»çº¿æ•°ä»“/OLAP_ONLINEåœ¨çº¿åˆ†æï¼‰
           - HIVE_OFFLINEï¼šç”¨äºç¦»çº¿æ•°æ®åˆ†æï¼Œé€šå¸¸æ‰¹é‡å¤„ç†
           - OLAP_ONLINEï¼šç”¨äºåœ¨çº¿å®æ—¶åˆ†æï¼Œéœ€è¦å¿«é€Ÿå“åº”
        7. process_domain: ä¸šåŠ¡åŸŸIDï¼ˆä»ä¸Šé¢å¯ç”¨ä¸šåŠ¡åŸŸåˆ—è¡¨ä¸­é€‰æ‹©æœ€åˆé€‚çš„ï¼‰
        8. safe_level: å®‰å…¨ç­‰çº§ï¼ˆS1æ™®é€šæ•°æ®/S2/S3/S4/S5å›½å¯†æ•°æ®ï¼‰
           - S1ï¼šæ™®é€šä¸šåŠ¡æ•°æ®
           - S2-S4ï¼šé€æ­¥å¢åŠ æ•æ„Ÿåº¦çš„æ•°æ®
           - S5ï¼šå›½å¯†çº§æ•æ„Ÿæ•°æ®
        9. business_owner: ä¸šåŠ¡è´Ÿè´£äººï¼ˆå¦‚æœç”¨æˆ·æœªæ˜ç¡®æåŠï¼Œè¯·æ ¹æ®æŒ‡æ ‡æ€§è´¨æ¨æ–­åˆé€‚çš„è´Ÿè´£äººè§’è‰²ï¼‰
        10. business_team: ä¸šåŠ¡å±ä¸»å›¢é˜Ÿï¼ˆå¦‚"äº§å“å›¢é˜Ÿ"ã€"è¿è¥å›¢é˜Ÿ"ã€"è´¢åŠ¡å›¢é˜Ÿ"ç­‰ï¼‰
        11. statistical_object: ç»Ÿè®¡çš„ä¸»ä½“ï¼ˆå¦‚"ç”¨æˆ·"ã€"è®¢å•"ã€"å•†å“"ã€"è®¿é—®"ã€"æ´»åŠ¨"ç­‰ï¼‰
        12. statistical_rule: ç»Ÿè®¡è§„åˆ™ï¼ˆä¸šåŠ¡å±‚é¢çš„ç»Ÿè®¡é€»è¾‘ï¼Œç”¨è‡ªç„¶è¯­è¨€æè¿°ï¼‰
        13. statistical_rule_it: ITå£å¾„ï¼ˆæŠ€æœ¯å®ç°çš„å…·ä½“SQLæˆ–è§„åˆ™ï¼Œæ›´æŠ€æœ¯åŒ–çš„æè¿°ï¼‰
        14. statistical_time: ç»Ÿè®¡æ—¶é—´ç²’åº¦ï¼ˆå®æ—¶ã€å°æ—¶ã€æ—¥ã€å‘¨ã€æœˆã€å­£åº¦ã€å¹´ç­‰ï¼‰
        15. unit: æŒ‡æ ‡å•ä½ï¼ˆæŒ‡æ ‡æ•°å€¼çš„è®¡é‡å•ä½ï¼‰
           - å¸¸è§å•ä½ï¼šä¸ªã€äººã€å…ƒã€%ã€æ¬¡ã€ç¬”ã€å¤©ã€å°æ—¶ã€GBã€MBç­‰
           - æ ¹æ®æŒ‡æ ‡åç§°å’Œä¸šåŠ¡åœºæ™¯æ¨æ–­åˆé€‚çš„å•ä½
           - å¦‚æœç”¨æˆ·æ˜ç¡®æåŠå•ä½åˆ™ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å•ä½
        16. business_caliber: ä¸šåŠ¡å£å¾„æè¿°ï¼ˆè¯¦ç»†çš„ä¸šåŠ¡å«ä¹‰è¯´æ˜ï¼Œè§£é‡Šè¿™ä¸ªæŒ‡æ ‡çš„å®é™…ä¸šåŠ¡æ„ä¹‰ï¼‰
        17. requirements: å…¶ä»–éœ€æ±‚åˆ—è¡¨ï¼ˆç”¨æˆ·æåˆ°çš„å…¶ä»–ç‰¹æ®Šè¦æ±‚ï¼‰

        æ“ä½œç±»å‹åˆ¤æ–­è§„åˆ™ï¼š
        - åŒ…å«"åˆ›å»º"ã€"æ–°å¢"ã€"å¢åŠ "ã€"å»ºç«‹ä¸€ä¸ª"ç­‰è¯æ±‡ â†’ create
        - åŒ…å«"ä¿®æ”¹"ã€"æ›´æ–°"ã€"å˜æ›´"ã€"è°ƒæ•´"ç­‰è¯æ±‡ â†’ update
        - åŒ…å«"æŸ¥è¯¢"ã€"æŸ¥çœ‹"ã€"æœç´¢"ã€"æ‰¾ä¸€ä¸‹"ã€"è·å–"ç­‰è¯æ±‡ â†’ query

        é‡è¦è¯´æ˜ï¼š
        - å¦‚æœç”¨æˆ·æ²¡æœ‰æ˜ç¡®æåˆ°çš„å­—æ®µï¼Œè¯·åŸºäºä¸šåŠ¡å¸¸è¯†å’ŒæŒ‡æ ‡æ€§è´¨è¿›è¡Œåˆç†æ¨æ–­
        - metric_nameå¿…é¡»å‡†ç¡®æå–ï¼Œè¿™æ˜¯åç»­æŸ¥è¯¢å’Œåˆ†æçš„å…³é”®
        - å¯¹äºæ´¾ç”ŸæŒ‡æ ‡(type=IB)ï¼Œéœ€è¦åœ¨statistical_ruleä¸­è¯´æ˜è®¡ç®—å…¬å¼
        - ä¸šåŠ¡å£å¾„åº”è¯¥ç®€æ´æ˜ç¡®ï¼Œè®©ä¸šåŠ¡äººå‘˜èƒ½å¤Ÿç†è§£æŒ‡æ ‡çš„å®é™…å«ä¹‰
        - ITå£å¾„åº”è¯¥æ›´æŠ€æœ¯åŒ–ï¼Œä¾¿äºå¼€å‘äººå‘˜ç†è§£å®ç°æ–¹å¼
        """)

        try:
            chain = prompt | self.llm | self.analysis_parser
            result = await chain.ainvoke({
                "user_input": user_input,
                "domains_text": domains_text,
                "format_instructions": self.analysis_parser.get_format_instructions()
            })

            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼å­˜å‚¨
            analysis_data = result.dict()

            # ç¡®å®šæ“ä½œç±»å‹
            operation_map = {
                "åˆ›å»º": "create", "æ–°å¢": "create", "å¢åŠ ": "create",
                "ä¿®æ”¹": "update", "æ›´æ–°": "update", "å˜æ›´": "update",
                "æŸ¥è¯¢": "query", "æŸ¥çœ‹": "query", "æœç´¢": "query"
            }

            operation_text = analysis_data.get("operation_type", "create")
            operation_type = MetricOperationType(operation_map.get(operation_text, "create"))
            analysis_data["operation_type"] = operation_type.value

            state["analysis_result"] = analysis_data
            self._logger.info(f"âœ… éœ€æ±‚åˆ†æå®Œæˆ: {operation_type.value} - æŒ‡æ ‡: {analysis_data.get('metric_name', 'N/A')}")

        except Exception as e:
            self._logger.error(f"âŒ åˆ†æéœ€æ±‚å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            default_analysis = {
                "operation_type": "create",
                "metric_name": "æ–°æŒ‡æ ‡",
                "business_owner": "å¾…æŒ‡å®š",
                "business_team": "å¾…æŒ‡å®š"
            }
            state["analysis_result"] = default_analysis

        return state

    async def _query_metric(self, state) -> Dict[str, Any]:
        """æŸ¥è¯¢æŒ‡æ ‡èŠ‚ç‚¹"""
        analysis_data = state.get("analysis_result", {})
        metric_name_zh = analysis_data.get("metric_name_zh", "")
        metric_name_en = analysis_data.get("metric_name", "")

        # ä¼˜å…ˆä½¿ç”¨ä¸­æ–‡åç§°æŸ¥è¯¢ï¼Œå¦‚æœæ²¡æœ‰ä¸­æ–‡åå†ä½¿ç”¨è‹±æ–‡å
        query_name = metric_name_zh if metric_name_zh else metric_name_en
        self._logger.info(f"ğŸ” æŸ¥è¯¢æŒ‡æ ‡: {query_name}")

        if not query_name:
            self._logger.warning("âš ï¸ æœªæä¾›æŒ‡æ ‡åç§°ï¼Œè·³è¿‡æŸ¥è¯¢")
            state["existing_metric"] = None
            return state

        try:
            # æ ¹æ®æŒ‡æ ‡ä¸­æ–‡åç§°æŸ¥è¯¢
            existing_metric = await query_metric_by_name_zh(query_name)

            if existing_metric:
                self._logger.info(f"âœ… æ‰¾åˆ°ç°æœ‰æŒ‡æ ‡: {existing_metric.get('nameZh', 'N/A')} ({existing_metric.get('code', 'N/A')})")
            else:
                self._logger.info(f"â„¹ï¸ æœªæ‰¾åˆ°æŒ‡æ ‡: {query_name}")

            state["existing_metric"] = existing_metric

        except Exception as e:
            self._logger.error(f"âŒ æŸ¥è¯¢æŒ‡æ ‡å¤±è´¥: {e}")
            state["existing_metric"] = None

        return state

    async def _execute_operation(self, state) -> Dict[str, Any]:
        """æ‰§è¡ŒæŒ‡æ ‡æ“ä½œèŠ‚ç‚¹"""
        user_input = state["user_input"]
        analysis_data = state.get("analysis_result", {})
        existing_metric = state.get("existing_metric")

        operation_type_str = analysis_data.get("operation_type", "create")
        operation_type = MetricOperationType(operation_type_str)

        self._logger.info(f"ğŸ”„ æ‰§è¡ŒæŒ‡æ ‡æ“ä½œ - {operation_type.value}")

        try:
            if operation_type == MetricOperationType.CREATE:
                # æ–°å¢é€»è¾‘ï¼šå¦‚æœæŸ¥è¯¢åˆ°å·²æœ‰æŒ‡æ ‡ï¼Œè¿”å›æŸ¥è¯¢ç»“æœï¼›å¦åˆ™åˆ›å»ºæ–°æŒ‡æ ‡
                if existing_metric:
                    self._logger.info(f"â„¹ï¸ æŒ‡æ ‡å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›: {existing_metric.get('nameZh', 'N/A')}")
                    state["final_metric"] = existing_metric
                    state["success"] = True
                else:
                    # ç”Ÿæˆæ–°æŒ‡æ ‡Schema
                    new_metric_schema = await self._create_new_metric_schema(user_input, analysis_data)
                    if new_metric_schema:
                        state["final_metric"] = new_metric_schema
                        state["success"] = True
                        self._logger.info(f"âœ… æ–°æŒ‡æ ‡Schemaç”ŸæˆæˆåŠŸ: {new_metric_schema.get('nameZh', 'N/A')}")
                    else:
                        state["final_metric"] = None
                        state["success"] = False

            elif operation_type == MetricOperationType.UPDATE:
                # ä¿®æ”¹é€»è¾‘ï¼šå¦‚æœæŸ¥è¯¢åˆ°å·²æœ‰æŒ‡æ ‡ï¼Œè¿›è¡Œåˆå¹¶æ›´æ–°ï¼›å¦åˆ™æç¤ºæœªæ‰¾åˆ°
                if existing_metric:
                    updated_metric_schema = self._update_existing_metric_schema(user_input, analysis_data, existing_metric)
                    if updated_metric_schema:
                        state["final_metric"] = updated_metric_schema
                        state["success"] = True
                        self._logger.info(f"âœ… æŒ‡æ ‡æ›´æ–°Schemaç”ŸæˆæˆåŠŸ: {updated_metric_schema.get('nameZh', 'N/A')}")
                    else:
                        state["final_metric"] = None
                        state["success"] = False
                else:
                    self._logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è¦æ›´æ–°çš„æŒ‡æ ‡: {analysis_data.get('metric_name', 'N/A')}")
                    state["final_metric"] = None
                    state["success"] = False

            elif operation_type == MetricOperationType.QUERY:
                # æŸ¥è¯¢é€»è¾‘ï¼šç›´æ¥è¿”å›æŸ¥è¯¢ç»“æœ
                if existing_metric:
                    self._logger.info(f"âœ… æŒ‡æ ‡æŸ¥è¯¢æˆåŠŸ: {existing_metric.get('nameZh', 'N/A')}")
                    state["final_metric"] = existing_metric
                    state["success"] = True
                else:
                    self._logger.info(f"â„¹ï¸ æœªæ‰¾åˆ°æŒ‡æ ‡: {analysis_data.get('metric_name', 'N/A')}")
                    state["final_metric"] = None
                    state["success"] = True  # æŸ¥è¯¢ä¸åˆ°ä¹Ÿç®—æˆåŠŸ

            else:
                self._logger.error(f"âŒ ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {operation_type}")
                state["final_metric"] = None
                state["success"] = False

        except Exception as e:
            self._logger.error(f"âŒ æ‰§è¡ŒæŒ‡æ ‡æ“ä½œå¤±è´¥: {e}")
            state["final_metric"] = None
            state["success"] = False

        return state

    async def _create_new_metric_schema(self, user_input: str, analysis_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """åˆ›å»ºæ–°æŒ‡æ ‡çš„Schema"""
        try:
            # è·å–å½“å‰æ—¶é—´æˆ³
            from datetime import datetime
            current_time = datetime.now().isoformat()

            metric_name_zh = analysis_data.get("metric_name_zh", "")
            metric_name_en = analysis_data.get("metric_name", "")

            if not metric_name_zh:
                self._logger.warning("âš ï¸ ç¼ºå°‘æŒ‡æ ‡ä¸­æ–‡åç§°ï¼Œæ— æ³•ç”ŸæˆSchema")
                return None

            # å¦‚æœæ²¡æœ‰è‹±æ–‡åï¼Œæ ¹æ®ä¸­æ–‡åç”Ÿæˆ
            if not metric_name_en:
                metric_name_en = metric_name_zh.lower().replace(" ", "_").replace("ï¼ˆ", "").replace("ï¼‰", "").replace("(", "").replace(")", "")

            # è·å–ä¸šåŠ¡åŸŸå¹¶æ™ºèƒ½åŒ¹é…
            process_domain = analysis_data.get("process_domain", "")

            # æ™ºèƒ½æ¨æ–­è´Ÿè´£äººå’Œå›¢é˜Ÿ
            business_owner = analysis_data.get("business_owner", "WAN")
            business_team = analysis_data.get("business_team", "æœ€å¼ºè´¢å¯Œå›¢é˜Ÿ")

            # æ„å»ºå®Œæ•´çš„ä¸šåŠ¡å£å¾„æè¿°
            business_caliber = analysis_data.get("business_caliber", "")
            if not business_caliber:
                stat_time = analysis_data.get("statistical_time", "å¾…å®šä¹‰")
                stat_object = analysis_data.get("statistical_object", "æŒ‡æ ‡")
                business_caliber = f"ç»Ÿè®¡{stat_time}çš„{metric_name_zh}ï¼Œåæ˜ {stat_object}çš„ç›¸å…³ä¸šåŠ¡æƒ…å†µ"

            # æ„å»ºæŠ€æœ¯å®ç°è¯´æ˜
            statistical_rule_it = analysis_data.get("statistical_rule_it", "")
            if not statistical_rule_it:
                statistical_rule = analysis_data.get("statistical_rule", "")
                if statistical_rule:
                    statistical_rule_it = f"æ ¹æ®ç»Ÿè®¡è§„åˆ™å®ç°: {statistical_rule}"
                else:
                    statistical_rule_it = f"åŸºäºä¸šåŠ¡è§„åˆ™è®¡ç®—{metric_name_zh}"

            # æ™ºèƒ½æ¨æ–­æŒ‡æ ‡å•ä½
            unit = analysis_data.get("unit", "ä¸ª")

            # ä»åˆ†ææ•°æ®ä¸­è·å–å€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ™ºèƒ½æ¨æ–­çš„é»˜è®¤å€¼
            metric_data = {
                "nameZh": metric_name_zh,
                "name": metric_name_en,
                "code": "",  # æ–°å¢æ—¶ä¸ºç©º
                "applicationScenarios": analysis_data.get("application_scenarios", "HIVE_OFFLINE"),
                "type": analysis_data.get("metric_type", "IA"),
                "lv": analysis_data.get("metric_level", "T2"),
                "processDomainId": process_domain,
                "safeLv": analysis_data.get("safe_level", "S1"),
                "businessCaliberDesc": business_caliber,
                "businessOwner": business_owner,
                "businessTeam": business_team,
                "statisticalObject": analysis_data.get("statistical_object", metric_name_zh.split("æ•°")[0] if "æ•°" in metric_name_zh else "ä¸šåŠ¡å¯¹è±¡"),
                "statisticalRule": analysis_data.get("statistical_rule", f"ç»Ÿè®¡{metric_name_zh}çš„ä¸šåŠ¡é€»è¾‘"),
                "statisticalRuleIt": statistical_rule_it,
                "statisticalTime": analysis_data.get("statistical_time", "æ—¥"),
                "unit": unit,
                "physicalInfoList": [] if analysis_data.get("metric_type") == "IA" else [{"metricId": ""}],
                "id": None,
                "create_time": current_time,
                "update_time": current_time
            }

            self._logger.info(f"âœ… ç”Ÿæˆæ–°æŒ‡æ ‡Schema: {metric_data.get('nameZh', 'N/A')} (åŸŸ: {process_domain}, è´Ÿè´£äºº: {business_owner})")
            return metric_data

        except Exception as e:
            self._logger.error(f"âŒ ç”Ÿæˆæ–°æŒ‡æ ‡Schemaå¤±è´¥: {e}")
            return None

    def _update_existing_metric_schema(self, user_input: str, analysis_data: Dict[str, Any], existing_metric: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æ›´æ–°ç°æœ‰æŒ‡æ ‡çš„Schema"""
        try:
            # è·å–å½“å‰æ—¶é—´æˆ³
            from datetime import datetime
            current_time = datetime.now().isoformat()

            # åˆå¹¶æ›´æ–°æ•°æ® - ä¼˜å…ˆä½¿ç”¨åˆ†ææ•°æ®ï¼Œæ²¡æœ‰åˆ™ä¿ç•™åŸæ•°æ®
            updated_metric = existing_metric.copy()

            # æ›´æ–°å„ä¸ªå­—æ®µï¼Œå¦‚æœåˆ†ææ•°æ®ä¸­æœ‰æ–°å€¼åˆ™ä½¿ç”¨æ–°å€¼ï¼Œå¦åˆ™ä¿ç•™åŸå€¼
            if analysis_data.get("metric_name_zh"):
                updated_metric["nameZh"] = analysis_data["metric_name_zh"]

            # è‹±æ–‡åï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„ï¼Œå¦‚æœç”¨æˆ·æ²¡æä¾›åˆ™æ ¹æ®ä¸­æ–‡åç”Ÿæˆ
            if analysis_data.get("metric_name"):
                updated_metric["name"] = analysis_data["metric_name"]
            elif analysis_data.get("metric_name_zh"):
                updated_metric["name"] = analysis_data["metric_name_zh"].lower().replace(" ", "_")

            if analysis_data.get("application_scenarios"):
                updated_metric["applicationScenarios"] = analysis_data["application_scenarios"]

            if analysis_data.get("metric_type"):
                updated_metric["type"] = analysis_data["metric_type"]
                # å¦‚æœæ˜¯æ´¾ç”ŸæŒ‡æ ‡ï¼Œéœ€è¦è®¾ç½®physicalInfoList
                if analysis_data["metric_type"] == "IB":
                    updated_metric["physicalInfoList"] = [{"metricId": ""}]
                else:
                    updated_metric["physicalInfoList"] = []

            if analysis_data.get("metric_level"):
                updated_metric["lv"] = analysis_data["metric_level"]

            if analysis_data.get("process_domain"):
                updated_metric["processDomainId"] = analysis_data["process_domain"]

            if analysis_data.get("safe_level"):
                updated_metric["safeLv"] = analysis_data["safe_level"]

            if analysis_data.get("business_owner"):
                updated_metric["businessOwner"] = analysis_data["business_owner"]

            if analysis_data.get("business_team"):
                updated_metric["businessTeam"] = analysis_data["business_team"]

            if analysis_data.get("statistical_object"):
                updated_metric["statisticalObject"] = analysis_data["statistical_object"]

            if analysis_data.get("statistical_rule"):
                updated_metric["statisticalRule"] = analysis_data["statistical_rule"]

            if analysis_data.get("statistical_rule_it"):
                updated_metric["statisticalRuleIt"] = analysis_data["statistical_rule_it"]

            if analysis_data.get("statistical_time"):
                updated_metric["statisticalTime"] = analysis_data["statistical_time"]

            if analysis_data.get("unit"):
                updated_metric["unit"] = analysis_data["unit"]

            # æ›´æ–°ä¸šåŠ¡å£å¾„ - ä¿ç•™åŸæœ‰å¹¶è¿½åŠ æ›´æ–°å†…å®¹
            if analysis_data.get("business_caliber"):
                original_caliber = existing_metric.get("businessCaliberDesc", "")
                update_info = analysis_data["business_caliber"]
                if original_caliber:
                    updated_metric["businessCaliberDesc"] = f"{original_caliber}ã€‚æ›´æ–°å†…å®¹: {update_info}"
                else:
                    updated_metric["businessCaliberDesc"] = update_info

            # æ›´æ–°æ—¶é—´æˆ³
            updated_metric["update_time"] = current_time

            self._logger.info(f"âœ… ç”Ÿæˆæ›´æ–°æŒ‡æ ‡Schema: {updated_metric.get('nameZh', 'N/A')}")
            return updated_metric

        except Exception as e:
            self._logger.error(f"âŒ ç”Ÿæˆæ›´æ–°æŒ‡æ ‡Schemaå¤±è´¥: {e}")
            return None

    

# æ³¨å†ŒMetricManagementAgent
from .registry import get_registry
from .base_agent import AgentConfig

def register_metric_agent():
    """æ³¨å†ŒæŒ‡æ ‡ç®¡ç†Agent"""
    registry = get_registry()

    default_metric_config = AgentConfig(
        name="metric_management",
        version="1.0.0",
        description="æŒ‡æ ‡ç®¡ç†Agentï¼Œæä¾›æŒ‡æ ‡çš„åˆ›å»ºã€æ›´æ–°å’ŒæŸ¥è¯¢åŠŸèƒ½",
        timeout=300,
        model_name="deepseek-ai/DeepSeek-V3.1"
    )

    from .base_agent import SimpleAgentFactory
    factory = SimpleAgentFactory(MetricManagementAgent)

    registry.register("metric_management", factory, default_metric_config, {
        "category": "data_governance",
        "capabilities": ["metric_creation", "metric_update", "metric_query", "metadata_generation"]
    })