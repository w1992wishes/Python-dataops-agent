"""
æŒ‡æ ‡ç®¡ç†Agent - å¤„ç†æŒ‡æ ‡çš„åˆ›å»ºã€æ›´æ–°å’ŒæŸ¥è¯¢
ä½¿ç”¨LangGraphå›ºå®šå·¥ä½œæµ
"""
from typing import Dict, List, Any, Optional, AsyncGenerator
from datetime import datetime
import traceback
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict, Annotated
from langgraph.graph.message import add_messages

from .base_agent import BaseAgent, AgentConfig, AgentResponse
from models.metric_schemas import MetricOperationResult, MetricInfo, MetricAnalysisResult
from tools.metric_tools import (
    query_metric_by_name_zh, get_metric_domains
)
from config.metric_prompts import (
    METRIC_ANALYSIS_PROMPT
)


def create_metric_info_safe(data: Dict[str, Any]) -> MetricInfo:
    """å®‰å…¨åˆ›å»ºMetricInfoå¯¹è±¡ï¼Œå¤„ç†ç¼ºå¤±å­—æ®µçš„æƒ…å†µ"""
    if not data:
        # å¦‚æœæ•°æ®ä¸ºç©ºï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤çš„MetricInfo
        return MetricInfo(
            nameZh="æœªçŸ¥æŒ‡æ ‡",
            name="unknown_metric",
            processDomainId="unknown",
            businessInfoMap={}
        )

    # æå–æ‰€æœ‰å¯èƒ½çš„å­—æ®µï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
    return MetricInfo(
        id=data.get("id"),
        nameZh=data.get("nameZh", "æœªçŸ¥æŒ‡æ ‡"),
        name=data.get("name", "unknown_metric"),
        code=data.get("code", ""),
        applicationScenarios=data.get("applicationScenarios", "HIVE_OFFLINE"),
        type=data.get("type", "IA"),
        lv=data.get("lv", "T2"),
        processDomainId=data.get("processDomainId", "unknown"),
        safeLv=data.get("safeLv", "S1"),
        businessCaliberDesc=data.get("businessCaliberDesc", ""),
        businessOwner=data.get("businessOwner", "å¾…æŒ‡å®š"),
        businessTeam=data.get("businessTeam", "å¾…æŒ‡å®š"),
        statisticalObject=data.get("statisticalObject", "å¾…å®šä¹‰"),
        statisticalRule=data.get("statisticalRule", "å¾…å®šä¹‰"),
        statisticalRuleIt=data.get("statisticalRuleIt", "å¾…å®šä¹‰"),
        statisticalTime=data.get("statisticalTime", "æ—¥"),
        unit=data.get("unit", "ä¸ª"),
        physicalInfoList=data.get("physicalInfoList"),
        businessInfoMap=data.get("businessInfoMap", {})
    )


class MetricManagementAgent(BaseAgent):
    """æŒ‡æ ‡ç®¡ç†Agent - ä½¿ç”¨LangGraphå›ºå®šå·¥ä½œæµ"""

    def __init__(self, config: AgentConfig):
        super().__init__(config)
        self._logger.info("ğŸ“Š åˆå§‹åŒ–æŒ‡æ ‡ç®¡ç†LangGraph Agent...")

        # åˆ›å»ºè¾“å‡ºè§£æå™¨
        self.analysis_parser = PydanticOutputParser(pydantic_object=MetricAnalysisResult)
        self.result_parser = PydanticOutputParser(pydantic_object=MetricOperationResult)

        # åˆ›å»ºLangGraphå·¥ä½œæµ
        self.graph = self._create_workflow()
        self._logger.info("âœ… æŒ‡æ ‡ç®¡ç†LangGraph Agentåˆå§‹åŒ–å®Œæˆ")

    def _create_workflow(self):
        """åˆ›å»ºLangGraphå›ºå®šå·¥ä½œæµ"""
        class AgentState(TypedDict):
            messages: Annotated[list, add_messages]
            user_input: str
            user_um: Optional[str]  # ç”¨æˆ·è´¦å·
            metric_name_zh: Optional[str]
            analysis_result: Optional[Dict[str, Any]]
            existing_metric: Optional[Dict[str, Any]]
            final_result: Optional[MetricOperationResult]
            success: bool

        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹ - å‚è€ƒetl_agentæ¨¡å¼ï¼Œç¬¬ä¸€æ­¥æŸ¥è¯¢æŒ‡æ ‡ä¿¡æ¯
        workflow.add_node("query_metric_info", self._query_metric_info)
        workflow.add_node("analyze_request", self._analyze_request)
        workflow.add_node("execute_operation", self._execute_operation)

        # æ·»åŠ æ¡ä»¶åˆ¤æ–­å‡½æ•°
        def should_continue_after_query(state):
            """åˆ¤æ–­æŸ¥è¯¢åæ˜¯å¦åº”è¯¥ç»§ç»­æ‰§è¡Œ"""
            # å¦‚æœå·²ç»æœ‰final_resultä¸”successä¸ºFalseï¼Œè¯´æ˜æƒé™æ£€æŸ¥å¤±è´¥ï¼Œç›´æ¥ç»“æŸ
            if state.get("final_result") and not state.get("success", True):
                return END
            return "analyze_request"

        # æ·»åŠ è¾¹ - å¸¦æƒé™æ§åˆ¶çš„æ‰§è¡Œæµç¨‹
        workflow.add_edge(START, "query_metric_info")
        workflow.add_conditional_edges(
            "query_metric_info",
            should_continue_after_query,
            {
                "analyze_request": "analyze_request",
                END: END
            }
        )
        workflow.add_edge("analyze_request", "execute_operation")
        workflow.add_edge("execute_operation", END)

        return workflow.compile()

    async def process(self, user_input: str, **kwargs) -> AgentResponse:
        """ä½¿ç”¨LangGraphå·¥ä½œæµå¤„ç†ç”¨æˆ·è¾“å…¥"""
        self._logger.info("ğŸ“Š å¼€å§‹æ‰§è¡ŒæŒ‡æ ‡ç®¡ç†å·¥ä½œæµ")

        initial_state = {
            "messages": [],
            "user_input": user_input,
            "user_um": kwargs.get("um"),
            "metric_name_zh": kwargs.get("metric_name_zh"),
            "analysis_result": None,
            "existing_metric": None,
            "final_result": None,
            "success": False
        }

        try:
            result = await self.graph.ainvoke(initial_state)
            final_result = result.get("final_result")
            success = result.get("success", False)

            if success and final_result:
                self._logger.info(f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {final_result.operation_type} - {final_result.status}")
                return AgentResponse(
                    success=True,
                    data={
                        "operation_result": final_result.model_dump(),
                        "agent_reply": final_result.message
                    }
                )
            else:
                self._logger.warning("âš ï¸ å·¥ä½œæµæ‰§è¡Œå®Œæˆä½†æœªæˆåŠŸ")
                return AgentResponse(
                    success=False,
                    error="å·¥ä½œæµæ‰§è¡Œå¤±è´¥"
                )

        except Exception as e:
            self._logger.error(f"ğŸ’¥ å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {str(e)}")
            self._logger.error(f"ğŸ’¥ å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸é“¾è·¯: {traceback.format_exc()}")
            return AgentResponse(
                success=False,
                error=f"å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {str(e)}"
            )

    async def process_stream(self, user_input: str, **kwargs) -> AsyncGenerator[Dict[str, Any], None]:
        """ä½¿ç”¨LangGraphçš„æµå¼å¤„ç†æ–¹æ³•"""
        self._logger.info("ğŸ“Š å¼€å§‹æ‰§è¡ŒæŒ‡æ ‡ç®¡ç†å·¥ä½œæµï¼ˆæµå¼ï¼‰")

        initial_state = {
            "messages": [],
            "user_input": user_input,
            "user_um": kwargs.get("um"),
            "metric_name_zh": kwargs.get("metric_name_zh"),
            "analysis_result": None,
            "existing_metric": None,
            "final_result": None,
            "success": False
        }

        try:
            # å…ˆå‘é€å¼€å§‹æ¶ˆæ¯
            yield {
                "step": "starting",
                "data": {"user_input": user_input},
                "message": "ğŸ” å¼€å§‹å¤„ç†æ‚¨çš„æŒ‡æ ‡ç®¡ç†éœ€æ±‚...",
                "timestamp": datetime.now().isoformat()
            }

            # ä½¿ç”¨LangGraphçš„æµå¼æ‰§è¡Œ
            async for output in self.graph.astream(initial_state):
                node_name = list(output.keys())[0]
                node_state = output[node_name]

                # æ„å»ºæµå¼è¾“å‡ºæ•°æ®
                chunk = {
                    "step": node_name,
                    "data": {
                        "node": node_name,
                        "state_summary": {
                            "has_analysis": node_state.get("analysis_result") is not None,
                            "has_existing_metric": node_state.get("existing_metric") is not None,
                            "has_final_result": node_state.get("final_result") is not None,
                            "success": node_state.get("success", False)
                        }
                    },
                    "message": f"æ‰§è¡Œæ­¥éª¤: {node_name}"
                }

                # æ·»åŠ æ­¥éª¤ç‰¹å®šçš„æ•°æ®
                if node_name == "query_metric_info":
                    existing = node_state.get("existing_metric")
                    final_result = node_state.get("final_result")

                    # å¦‚æœæœ‰final_resultä¸”successä¸ºFalseï¼Œè¯´æ˜æƒé™æ£€æŸ¥å¤±è´¥
                    if final_result and not node_state.get("success", True):
                        chunk["data"]["final_result"] = final_result.model_dump()
                        chunk["message"] = f"ğŸš« {final_result.message}"
                    elif existing:
                        chunk["data"]["existing_metric"] = existing
                        edit_permission = existing.get('editPermission', 0)
                        permission_text = "æœ‰ç¼–è¾‘æƒé™" if edit_permission == 1 else "åªè¯»æƒé™"
                        chunk["message"] = f"ğŸ“‹ æŸ¥è¯¢åˆ°å·²å­˜åœ¨æŒ‡æ ‡: {existing.get('nameZh', 'N/A')} - {permission_text}"
                    else:
                        chunk["message"] = "â„¹ï¸ æœªæ‰¾åˆ°å·²å­˜åœ¨æŒ‡æ ‡"

                elif node_name == "analyze_request":
                    analysis = node_state.get("analysis_result", {})
                    if analysis:
                        chunk["data"]["analysis"] = analysis
                        metric_info = analysis.get('metric_info', {})
                        metric_name = metric_info.get('nameZh', 'N/A') if metric_info else 'N/A'
                        chunk["message"] = f"âœ… éœ€æ±‚åˆ†æå®Œæˆ: {analysis.get('operation_type', 'N/A')} - {metric_name}"
                    else:
                        chunk["message"] = "ğŸ“ æ­£åœ¨åˆ†ææ‚¨çš„éœ€æ±‚..."

                elif node_name == "execute_operation":
                    final_result = node_state.get("final_result")
                    success = node_state.get("success", False)
                    if final_result and success:
                        chunk["data"]["final_result"] = final_result.model_dump()
                        chunk["message"] = f"ğŸ‰ æŒ‡æ ‡å¤„ç†å®Œæˆ: {final_result.operation_type} - {final_result.status}"
                    else:
                        chunk["message"] = "âŒ æŒ‡æ ‡å¤„ç†å¤±è´¥"

                chunk["timestamp"] = datetime.now().isoformat()
                yield chunk

            # å‘é€æœ€ç»ˆå®Œæˆæ¶ˆæ¯
            final_chunk = {
                "step": "completed",
                "data": {"workflow_completed": True},
                "message": "âœ… æŒ‡æ ‡ç®¡ç†å·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                "timestamp": datetime.now().isoformat()
            }
            yield final_chunk

        except Exception as e:
            self._logger.error(f"ğŸ’¥ æµå¼æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            self._logger.error(f"ğŸ’¥ æµå¼æ‰§è¡Œå¼‚å¸¸é“¾è·¯: {traceback.format_exc()}")
            error_chunk = {
                "step": "error",
                "data": {"error": str(e)},
                "message": f"âŒ å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
            yield error_chunk

    # ========== LangGraph å·¥ä½œæµèŠ‚ç‚¹ ==========

    async def _analyze_request(self, state) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·éœ€æ±‚èŠ‚ç‚¹ - ç»“åˆå·²æŸ¥è¯¢çš„æŒ‡æ ‡ä¿¡æ¯åˆ†æéœ€æ±‚"""
        user_input = state["user_input"]
        existing_metric = state.get("existing_metric")
        metric_name_zh = state.get("metric_name_zh")

        self._logger.info("ğŸ” åˆ†æç”¨æˆ·æŒ‡æ ‡ç®¡ç†éœ€æ±‚")

        # è·å–ä¸šåŠ¡åŸŸä¿¡æ¯
        try:
            domains_info = get_metric_domains()
            domains_text = "\n".join([f"- {domain['id']}: {domain['nameZh']}" for domain in domains_info])
        except Exception as e:
            self._logger.warning(f"âš ï¸ è·å–ä¸šåŠ¡åŸŸä¿¡æ¯å¤±è´¥: {str(e)}")
            self._logger.warning(f"âš ï¸ è·å–ä¸šåŠ¡åŸŸå¼‚å¸¸é“¾è·¯: {traceback.format_exc()}")
            domains_text = ""

        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æç¤ºè¯å’Œæ ¼å¼åŒ–æŒ‡ä»¤
        format_instructions = self.analysis_parser.get_format_instructions()
        prompt = ChatPromptTemplate.from_template(METRIC_ANALYSIS_PROMPT)

        try:
            chain = prompt | self.llm
            # æ„å»ºä¼ é€’ç»™LLMçš„å‚æ•°ï¼ŒåŒ…å«å·²æŸ¥è¯¢çš„æŒ‡æ ‡ä¿¡æ¯
            llm_params = {
                "user_input": user_input,
                "domains_text": domains_text,
                "format_instructions": format_instructions
            }

            # å¦‚æœæœ‰å·²å­˜åœ¨çš„æŒ‡æ ‡ä¿¡æ¯ï¼Œä¼ é€’ç»™LLM
            if existing_metric:
                # ç¡®ä¿existing_metricæ˜¯å­—å…¸æ ¼å¼
                if hasattr(existing_metric, 'model_dump'):
                    metric_data = existing_metric.model_dump()
                else:
                    metric_data = existing_metric
                llm_params["existing_metric_info"] = f"å·²å­˜åœ¨æŒ‡æ ‡ä¿¡æ¯: {metric_data}"
            else:
                llm_params["existing_metric_info"] = "æœªæ‰¾åˆ°å·²å­˜åœ¨çš„æŒ‡æ ‡ä¿¡æ¯"

            # å¦‚æœæœ‰ä¼ å…¥æŒ‡æ ‡ä¸­æ–‡åï¼Œä¼ é€’ç»™LLM
            if metric_name_zh:
                llm_params["provided_metric_name_zh"] = metric_name_zh

            result = await chain.ainvoke(llm_params)

            # ä½¿ç”¨Pydanticè§£æå™¨è§£æLLMè¿”å›çš„ç»“æœ
            analysis_result = self.analysis_parser.parse(result.content)

            state["analysis_result"] = analysis_result.model_dump()

            if analysis_result.metric_info:
                metric_name = analysis_result.metric_info.nameZh
                self._logger.info(f"âœ… éœ€æ±‚åˆ†æå®Œæˆ: {analysis_result.operation_type} - {metric_name}")
            else:
                self._logger.info(f"âœ… éœ€æ±‚åˆ†æå®Œæˆ: {analysis_result.operation_type} - æ— æŒ‡æ ‡ä¿¡æ¯")

        except Exception as e:
            self._logger.error(f"âŒ åˆ†æéœ€æ±‚å¤±è´¥: {str(e)}")
            self._logger.error(f"âŒ åˆ†æéœ€æ±‚å¼‚å¸¸é“¾è·¯: {traceback.format_exc()}")
            # ä½¿ç”¨é»˜è®¤åˆ†æç»“æœ
            default_analysis = MetricAnalysisResult(
                operation_type="create",
                metric_info=None
            )
            state["analysis_result"] = default_analysis.model_dump()

        return state

    async def _execute_operation(self, state) -> Dict[str, Any]:
        """æ‰§è¡ŒæŒ‡æ ‡æ“ä½œèŠ‚ç‚¹"""
        user_input = state["user_input"]
        analysis_data = state.get("analysis_result", {})
        existing_metric = state.get("existing_metric")

        operation_type = analysis_data.get("operation_type", "create")

        # ä»åˆ†æç»“æœä¸­æå–metric_infoï¼Œå¦‚æœæ˜¯å­—å…¸åˆ™è½¬æ¢ä¸ºMetricInfoå¯¹è±¡
        metric_info_data = analysis_data.get("metric_info", {})
        if isinstance(metric_info_data, dict):
            analyzed_metric_info = create_metric_info_safe(metric_info_data)
        else:
            analyzed_metric_info = metric_info_data

        self._logger.info(f"ğŸ”„ æ‰§è¡ŒæŒ‡æ ‡æ“ä½œ - {operation_type}")
        if analyzed_metric_info:
            self._logger.info(f"ğŸ“Š è§£æçš„æŒ‡æ ‡ä¿¡æ¯: {analyzed_metric_info.nameZh}")

        try:
            # æ ¹æ®æ“ä½œç±»å‹å’ŒæŸ¥è¯¢ç»“æœæ‰§è¡Œç›¸åº”é€»è¾‘
            if operation_type == "create":
                if existing_metric:
                    # æŒ‡æ ‡å·²å­˜åœ¨
                    existing_metric_info = create_metric_info_safe(existing_metric)
                    final_result = MetricOperationResult(
                            operation_type="create",
                            status="exist",
                            message=f"æŒ‡æ ‡å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤åˆ›å»º: {existing_metric_info.nameZh}",
                            metric_info=None,
                            existing_metric=existing_metric_info
                        )
                else:
                    # åˆ›å»ºæ–°æŒ‡æ ‡ - ç›´æ¥ä½¿ç”¨åˆ†æå¾—å‡ºçš„MetricInfo
                    if analyzed_metric_info:
                        # ä¸ºæ–°æŒ‡æ ‡è®¾ç½®IDå’Œåˆ›å»ºæ—¶é—´
                        analyzed_metric_info.id = None
                        # å¦‚æœä¸šåŠ¡å£å¾„æè¿°ä¸ºç©ºï¼Œä½¿ç”¨ç”¨æˆ·è¾“å…¥
                        if not analyzed_metric_info.businessCaliberDesc:
                            analyzed_metric_info.businessCaliberDesc = f"åŸºäºç”¨æˆ·éœ€æ±‚åˆ›å»ºçš„æŒ‡æ ‡: {user_input}"

                        final_result = MetricOperationResult(
                            operation_type="create",
                            status="success",
                            message=f"æŒ‡æ ‡åˆ›å»ºæˆåŠŸ: {analyzed_metric_info.nameZh}",
                            metric_info=analyzed_metric_info,
                            existing_metric=None
                        )
                    else:
                        final_result = MetricOperationResult(
                            operation_type="create",
                            status="error",
                            message="åˆ†æç»“æœä¸­ç¼ºå°‘æŒ‡æ ‡ä¿¡æ¯",
                            metric_info=None,
                            existing_metric=None
                        )

            elif operation_type == "update":
                if existing_metric:
                    # ä¿®æ”¹ç°æœ‰æŒ‡æ ‡ - åˆå¹¶åˆ†æå¾—å‡ºçš„ä¿¡æ¯å’Œç°æœ‰æŒ‡æ ‡ä¿¡æ¯
                    existing_metric_info = create_metric_info_safe(existing_metric)

                        # æ›´æ–°ç°æœ‰æŒ‡æ ‡çš„æŸäº›å­—æ®µï¼ˆå¦‚æœåˆ†æç»“æœä¸­æœ‰å€¼ï¼‰
                    if analyzed_metric_info:
                        if analyzed_metric_info.nameZh:
                            existing_metric_info.nameZh = analyzed_metric_info.nameZh
                        if analyzed_metric_info.name:
                            existing_metric_info.name = analyzed_metric_info.name
                        if analyzed_metric_info.businessCaliberDesc:
                            existing_metric_info.businessCaliberDesc = f"{existing_metric_info.businessCaliberDesc}ã€‚æ›´æ–°éœ€æ±‚: {user_input}"

                    final_result = MetricOperationResult(
                        operation_type="update",
                        status="success",
                        message=f"æŒ‡æ ‡ä¿®æ”¹æˆåŠŸ: {existing_metric_info.nameZh}",
                        metric_info=existing_metric_info,
                        existing_metric=None
                    )
                else:
                    # æŒ‡æ ‡ä¸å­˜åœ¨
                    metric_name = analyzed_metric_info.nameZh if analyzed_metric_info else "æœªçŸ¥æŒ‡æ ‡"
                    final_result = MetricOperationResult(
                        operation_type="update",
                        status="not_exist",
                        message=f"æŒ‡æ ‡ä¸å­˜åœ¨ï¼Œæ— æ³•ä¿®æ”¹: {metric_name}",
                        metric_info=None,
                        existing_metric=None
                    )

            elif operation_type == "query":
                if existing_metric:
                    # æŸ¥è¯¢æˆåŠŸ
                    existing_metric_info = create_metric_info_safe(existing_metric)
                    final_result = MetricOperationResult(
                        operation_type="query",
                        status="success",
                        message=f"æŸ¥è¯¢æˆåŠŸ: {existing_metric_info.nameZh}",
                        metric_info=existing_metric_info,
                        existing_metric=None
                    )
                else:
                    # æŸ¥è¯¢æ— ç»“æœ - è¿”å›åˆ†æå¾—å‡ºçš„æŒ‡æ ‡ä¿¡æ¯ä½œä¸ºå‚è€ƒ
                    if analyzed_metric_info:
                        final_result = MetricOperationResult(
                            operation_type="query",
                            status="not_exist",
                            message=f"æœªæ‰¾åˆ°æŒ‡æ ‡ï¼Œä½†ä¸ºæ‚¨åˆ†æäº†ç›¸ä¼¼æŒ‡æ ‡: {analyzed_metric_info.nameZh}",
                            metric_info=analyzed_metric_info,
                            existing_metric=None
                        )
                    else:
                        final_result = MetricOperationResult(
                            operation_type="query",
                            status="not_exist",
                            message="æœªæ‰¾åˆ°æŒ‡æ ‡ä¸”æ— æ³•åˆ†æç›¸å…³ä¿¡æ¯",
                            metric_info=None,
                            existing_metric=None
                        )
            else:
                final_result = MetricOperationResult(
                    operation_type="unknown",
                    status="error",
                    message=f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {operation_type}",
                    metric_info=None,
                    existing_metric=None
                )

            # ä½¿ç”¨result_parseréªŒè¯æœ€ç»ˆç»“æœ
            state["final_result"] = final_result
            state["success"] = True
            self._logger.info(f"âœ… æŒ‡æ ‡æ“ä½œæ‰§è¡Œå®Œæˆ: {final_result.operation_type} - {final_result.status}")


        except Exception as e:
            self._logger.error(f"âŒ æ‰§è¡ŒæŒ‡æ ‡æ“ä½œå¤±è´¥: {str(e)}")
            self._logger.error(f"âŒ æ‰§è¡ŒæŒ‡æ ‡æ“ä½œå¼‚å¸¸é“¾è·¯: {traceback.format_exc()}")
            error_result = MetricOperationResult(
                operation_type=operation_type,
                status="error",
                message=f"æ“ä½œæ‰§è¡Œå¤±è´¥: {str(e)}",
                metric_info=None,
                existing_metric=None
            )
            state["final_result"] = error_result
            state["success"] = False

        return state

    async def _query_metric_info(self, state) -> Dict[str, Any]:
        """æŸ¥è¯¢æŒ‡æ ‡ä¿¡æ¯èŠ‚ç‚¹"""
        user_um = state.get("user_um")
        metric_name_zh = state.get("metric_name_zh")

        self._logger.info(f"ğŸ” [æŸ¥è¯¢æŒ‡æ ‡ä¿¡æ¯èŠ‚ç‚¹] å¼€å§‹æŸ¥è¯¢æŒ‡æ ‡ä¿¡æ¯: userUM={user_um}, metric_name_zh={metric_name_zh}")

        try:
            # ä½¿ç”¨æ‰©å±•åçš„query_metric_by_name_zhæŸ¥è¯¢æŒ‡æ ‡åŠç”¨æˆ·æƒé™
            existing_metric = await query_metric_by_name_zh(metric_name_zh, user_um)

            if existing_metric:
                state["existing_metric"] = existing_metric
                edit_permission = existing_metric.get('editPermission', 0)
                self._logger.info(f"âœ… [æŸ¥è¯¢æŒ‡æ ‡ä¿¡æ¯èŠ‚ç‚¹] æ‰¾åˆ°å·²å­˜åœ¨æŒ‡æ ‡: {existing_metric.get('nameZh', 'N/A')} - ç”¨æˆ·ç¼–è¾‘æƒé™: {edit_permission}")

                # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰ç¼–è¾‘æƒé™
                if edit_permission == 0:
                    # è½¬æ¢å­—å…¸ä¸ºMetricInfoå¯¹è±¡
                    existing_metric_info = create_metric_info_safe(existing_metric)

                    error_result = MetricOperationResult(
                        operation_type="update",
                        status="error",
                        message=f"å¯¹æŒ‡æ ‡ {existing_metric.get('nameZh', 'N/A')} æ²¡æœ‰ç¼–è¾‘æƒé™ï¼Œæ— æ³•æ‰§è¡Œä¿®æ”¹æ“ä½œ",
                        metric_info=None,
                        existing_metric=existing_metric_info
                    )
                    state["final_result"] = error_result
                    state["success"] = False
                    state["existing_metric"] = existing_metric
                    self._logger.warning(f"ğŸš« [æŸ¥è¯¢æŒ‡æ ‡ä¿¡æ¯èŠ‚ç‚¹] ç”¨æˆ· {user_um} æ— ç¼–è¾‘æƒé™ä½†è¦æ±‚ä¿®æ”¹æŒ‡æ ‡ï¼Œé€šè¿‡æµç¨‹æ§åˆ¶æ‹’ç»æ“ä½œ")
                    return state

            else:
                state["existing_metric"] = None
                self._logger.info(f"â„¹ï¸ [æŸ¥è¯¢æŒ‡æ ‡ä¿¡æ¯èŠ‚ç‚¹] æœªæ‰¾åˆ°å·²å­˜åœ¨æŒ‡æ ‡")

        except Exception as e:
            self._logger.error(f"âŒ [æŸ¥è¯¢æŒ‡æ ‡ä¿¡æ¯èŠ‚ç‚¹] æŸ¥è¯¢æŒ‡æ ‡ä¿¡æ¯å¤±è´¥: {str(e)}")
            state["existing_metric"] = None

        return state

# æ³¨å†ŒMetricManagementAgent
from .registry import get_registry

def register_metric_agent():
    """æ³¨å†ŒæŒ‡æ ‡ç®¡ç†Agent"""
    registry = get_registry()

    default_metric_config = AgentConfig(
        name="metric_management",
        version="3.0.0",
        description="æŒ‡æ ‡ç®¡ç†Agentï¼Œæä¾›åŸºäºLangGraphçš„æŒ‡æ ‡åˆ›å»ºã€æ›´æ–°å’ŒæŸ¥è¯¢åŠŸèƒ½",
        timeout=300,
        model_name="deepseek-ai/DeepSeek-V3.1-Terminus"
    )

    from .base_agent import SimpleAgentFactory
    factory = SimpleAgentFactory(MetricManagementAgent)

    registry.register("metric_management", factory, default_metric_config, {
        "category": "data_governance",
        "capabilities": ["metric_creation", "metric_update", "metric_query", "metadata_generation"],
        "agent_type": "langgraph_workflow"
    })